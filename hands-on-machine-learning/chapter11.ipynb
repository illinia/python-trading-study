{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.594564Z",
     "start_time": "2023-08-16T15:50:43.805135Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 텐서플로 ≥2.0 필수\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.595512Z",
     "start_time": "2023-08-16T15:50:47.414962Z"
    }
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.596477Z",
     "start_time": "2023-08-16T15:50:47.421089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.2, 1.2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), 'b-', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.axis([-5, 5, -0.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier 초기화와 He 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.596744Z",
     "start_time": "2023-08-16T15:50:47.493078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'HeNormal',\n",
       " 'HeUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'LecunNormal',\n",
       " 'LecunUniform',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'random_normal',\n",
       " 'random_uniform',\n",
       " 'serialize',\n",
       " 'truncated_normal',\n",
       " 'variance_scaling',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.596918Z",
     "start_time": "2023-08-16T15:50:47.509052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x291cb64f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.597104Z",
     "start_time": "2023-08-16T15:50:47.518989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x291d213a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation='relu', kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수렴하지 않는 활성화 함수\n",
    "### LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.597192Z",
     "start_time": "2023-08-16T15:50:47.522260Z"
    }
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha * z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.597449Z",
     "start_time": "2023-08-16T15:50:47.533512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.5, 4.2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), 'b-', linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.axis([-5, 5, -0.5, 4.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.597685Z",
     "start_time": "2023-08-16T15:50:47.584351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'mish',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.597870Z",
     "start_time": "2023-08-16T15:50:47.588937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if 'relu' in m.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.597954Z",
     "start_time": "2023-08-16T15:50:47.592171Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.598041Z",
     "start_time": "2023-08-16T15:50:48.017765Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:50:54.598993Z",
     "start_time": "2023-08-16T15:50:48.047862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:06.455605Z",
     "start_time": "2023-08-16T15:50:48.056519Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=10,\n",
    "#                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:06.491289Z",
     "start_time": "2023-08-16T15:51:06.459557Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:06.491711Z",
     "start_time": "2023-08-16T15:51:06.482220Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:25.967265Z",
     "start_time": "2023-08-16T15:51:06.489614Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=10,\n",
    "#                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:25.969415Z",
     "start_time": "2023-08-16T15:51:25.967073Z"
    }
   },
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.028407Z",
     "start_time": "2023-08-16T15:51:25.971944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29bcca3d0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), 'b-', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.032556Z",
     "start_time": "2023-08-16T15:51:26.029063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x29bcf5f40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation='elu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.035094Z",
     "start_time": "2023-08-16T15:51:26.033370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x29bcfcc10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation='selu',\n",
    "                   kernel_initializer='lecun_normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.041706Z",
     "start_time": "2023-08-16T15:51:26.037258Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.558854Z",
     "start_time": "2023-08-16T15:51:26.040970Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='selu',\n",
    "                             kernel_initializer='lecun_normal'))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation='selu',\n",
    "                                 kernel_initializer='lecun_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.565106Z",
     "start_time": "2023-08-16T15:51:26.557539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:51:26.890157Z",
     "start_time": "2023-08-16T15:51:26.566695Z"
    }
   },
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:52:45.653355Z",
     "start_time": "2023-08-16T15:51:26.889703Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:52:45.663584Z",
     "start_time": "2023-08-16T15:52:45.657563Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:52:46.113562Z",
     "start_time": "2023-08-16T15:52:45.665959Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:52:46.126413Z",
     "start_time": "2023-08-16T15:52:46.114430Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:53:38.854723Z",
     "start_time": "2023-08-16T15:52:46.122579Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:53:38.874870Z",
     "start_time": "2023-08-16T15:53:38.848217Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:53:38.891240Z",
     "start_time": "2023-08-16T15:53:38.875763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 784)               3136      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271346 (1.04 MB)\n",
      "Trainable params: 268978 (1.03 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:53:38.891657Z",
     "start_time": "2023-08-16T15:53:38.886811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:53:38.964485Z",
     "start_time": "2023-08-16T15:53:38.888047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:02.123084Z",
     "start_time": "2023-08-16T15:53:38.893961Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=10,\n",
    "#                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:02.157613Z",
     "start_time": "2023-08-16T15:54:02.122451Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:02.158095Z",
     "start_time": "2023-08-16T15:54:02.151485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.426486Z",
     "start_time": "2023-08-16T15:54:02.157789Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=10,\n",
    "#                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레이디언트 클리핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.430623Z",
     "start_time": "2023-08-16T15:54:25.426368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 훈련된 층 재사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.506781Z",
     "start_time": "2023-08-16T15:54:25.429061Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6)\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32)\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.511743Z",
     "start_time": "2023-08-16T15:54:25.507773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.515901Z",
     "start_time": "2023-08-16T15:54:25.511112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.522597Z",
     "start_time": "2023-08-16T15:54:25.514759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.525413Z",
     "start_time": "2023-08-16T15:54:25.518562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.559885Z",
     "start_time": "2023-08-16T15:54:25.536136Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.571439Z",
     "start_time": "2023-08-16T15:54:25.540316Z"
    }
   },
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
    "model_A.add(keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:25.610477Z",
     "start_time": "2023-08-16T15:54:25.572357Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:59.478419Z",
     "start_time": "2023-08-16T15:54:25.581378Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "#                       validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:59.504827Z",
     "start_time": "2023-08-16T15:54:59.478292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taemin/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_A.save('my_model_A.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:59.541761Z",
     "start_time": "2023-08-16T15:54:59.500863Z"
    }
   },
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
    "model_B.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:54:59.577309Z",
     "start_time": "2023-08-16T15:54:59.523476Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model_B.compile(loss='binary_crossentropy',\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:00.525913Z",
     "start_time": "2023-08-16T15:54:59.529738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6167 - accuracy: 0.7200 - val_loss: 0.5647 - val_accuracy: 0.7191\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7900 - val_loss: 0.4498 - val_accuracy: 0.8124\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8850 - val_loss: 0.3778 - val_accuracy: 0.8671\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.9300 - val_loss: 0.3262 - val_accuracy: 0.9026\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2489 - accuracy: 0.9600 - val_loss: 0.2886 - val_accuracy: 0.9199\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2148 - accuracy: 0.9750 - val_loss: 0.2591 - val_accuracy: 0.9351\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1896 - accuracy: 0.9800 - val_loss: 0.2365 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1695 - accuracy: 0.9800 - val_loss: 0.2176 - val_accuracy: 0.9544\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.9850 - val_loss: 0.2015 - val_accuracy: 0.9574\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.9850 - val_loss: 0.1884 - val_accuracy: 0.9615\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9900 - val_loss: 0.1766 - val_accuracy: 0.9665\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9900 - val_loss: 0.1670 - val_accuracy: 0.9726\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1075 - accuracy: 0.9950 - val_loss: 0.1585 - val_accuracy: 0.9726\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9950 - val_loss: 0.1506 - val_accuracy: 0.9757\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0932 - accuracy: 0.9950 - val_loss: 0.1438 - val_accuracy: 0.9736\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.9950 - val_loss: 0.1380 - val_accuracy: 0.9757\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9767\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9767\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9777\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:00.541770Z",
     "start_time": "2023-08-16T15:55:00.525335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275801 (1.05 MB)\n",
      "Trainable params: 275801 (1.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:00.605863Z",
     "start_time": "2023-08-16T15:55:00.534728Z"
    }
   },
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model('my_model_A.h5')\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:00.613501Z",
     "start_time": "2023-08-16T15:55:00.593810Z"
    }
   },
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:00.622988Z",
     "start_time": "2023-08-16T15:55:00.613364Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss='binary_crossentropy',\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.799165Z",
     "start_time": "2023-08-16T15:55:00.620231Z"
    }
   },
   "outputs": [],
   "source": [
    "# history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "#                            validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "# for layer in model_B_on_A.layers[:-1]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# model_B_on_A.compile(loss='binary_crossentropy',\n",
    "#                      optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "#                      metrics=['accuracy'])\n",
    "# history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "#                            validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.885149Z",
     "start_time": "2023-08-16T15:55:01.799044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 691us/step - loss: 0.1111 - accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11108828336000443, 0.9769999980926514]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.935291Z",
     "start_time": "2023-08-16T15:55:01.869399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 719us/step - loss: 0.9656 - accuracy: 0.3195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9656099677085876, 0.31949999928474426]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고속 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.945481Z",
     "start_time": "2023-08-16T15:55:01.935839Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.sgd.SGD at 0x2a1d235e0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.945727Z",
     "start_time": "2023-08-16T15:55:01.939574Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.sgd.SGD at 0x306b9d910>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.967291Z",
     "start_time": "2023-08-16T15:55:01.943321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.adagrad.Adagrad at 0x306b9d700>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.Adagrad(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:01.967674Z",
     "start_time": "2023-08-16T15:55:01.947331Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.rmsprop.RMSprop at 0x306bb19d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:02.020056Z",
     "start_time": "2023-08-16T15:55:01.951050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.adam.Adam at 0x306bb1d30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:02.020640Z",
     "start_time": "2023-08-16T15:55:01.954590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adamax` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adamax`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.adamax.Adamax at 0x306dcd400>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:02.020787Z",
     "start_time": "2023-08-16T15:55:01.958966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.optimizers.nadam.Nadam at 0x306dcd070>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:02.020860Z",
     "start_time": "2023-08-16T15:55:01.962395Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:02.127079Z",
     "start_time": "2023-08-16T15:55:01.967748Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:50.880025Z",
     "start_time": "2023-08-16T15:55:01.985101Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_epochs = 25\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:50.882374Z",
     "start_time": "2023-08-16T15:55:50.879860Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:50.884616Z",
     "start_time": "2023-08-16T15:55:50.882148Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:55:50.914657Z",
     "start_time": "2023-08-16T15:55:50.886737Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:57:34.604019Z",
     "start_time": "2023-08-16T15:55:50.902639Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid),\n",
    "#                     callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:57:34.609600Z",
     "start_time": "2023-08-16T15:57:34.606414Z"
    }
   },
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:57:34.652634Z",
     "start_time": "2023-08-16T15:57:34.613254Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:59:25.756569Z",
     "start_time": "2023-08-16T15:57:34.635311Z"
    }
   },
   "outputs": [],
   "source": [
    "# s = 20 * len(X_train) // 32\n",
    "# exp_decay = ExponentialDecay(s)\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid),\n",
    "#                     callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:59:25.759450Z",
     "start_time": "2023-08-16T15:59:25.756411Z"
    }
   },
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T15:59:25.763397Z",
     "start_time": "2023-08-16T15:59:25.760054Z"
    }
   },
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T16:49:21.329931Z",
     "start_time": "2023-08-16T15:59:25.764786Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "#     keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "# n_epochs = 25\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid),\n",
    "#                     callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T16:49:21.353614Z",
     "start_time": "2023-08-16T16:49:21.345750Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:22:25.634144Z",
     "start_time": "2023-08-16T16:49:21.353199Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "#     keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# n_epochs = 25\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid),\n",
    "#                     callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:23:12.199458Z",
     "start_time": "2023-08-16T17:22:25.648162Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "#     keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "# s = 20 * len(X_train) // 32\n",
    "# learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "# optimizer = keras.optimizers.SGD(learning_rate)\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# n_epochs = 25\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 규제를 사용해 과대적합 피하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:23:12.206628Z",
     "start_time": "2023-08-16T17:23:12.203216Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation='elu',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:23:21.040856Z",
     "start_time": "2023-08-16T17:23:12.208853Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation='elu',\n",
    "#                        kernel_initializer='he_normal',\n",
    "#                        kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "#     keras.layers.Dense(100, activation='elu',\n",
    "#                        kernel_initializer='he_normal',\n",
    "#                        kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "#     keras.layers.Dense(10, activation='softmax',\n",
    "#                        kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# ])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "# n_epochs = 2\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:23:30.014237Z",
     "start_time": "2023-08-16T17:23:21.043519Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "\n",
    "# RegularizedDense = partial(keras.layers.Dense,\n",
    "#                            activation='elu',\n",
    "#                            kernel_initializer='he_normal',\n",
    "#                            kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     RegularizedDense(300),\n",
    "#     RegularizedDense(100),\n",
    "#     RegularizedDense(10, activation='softmax')\n",
    "# ])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "# n_epochs = 2\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T17:38:55.195827Z",
     "start_time": "2023-08-16T17:38:44.463354Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dropout(rate=0.2),\n",
    "#     keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "#     keras.layers.Dropout(rate=0.2),\n",
    "#     keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "#     keras.layers.Dropout(rate=0.2),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "# n_epochs = 2\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "#                     validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:31:59.846311Z",
     "start_time": "2023-08-16T18:31:59.820592Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:33:24.347194Z",
     "start_time": "2023-08-16T18:33:20.043734Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:33:41.794183Z",
     "start_time": "2023-08-16T18:33:41.715892Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:33:59.716803Z",
     "start_time": "2023-08-16T18:33:59.649370Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "\n",
       "       [[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:35:06.952361Z",
     "start_time": "2023-08-16T18:35:06.893220Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:35:35.804265Z",
     "start_time": "2023-08-16T18:35:35.750675Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:35:55.281770Z",
     "start_time": "2023-08-16T18:35:55.219874Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:36:13.887096Z",
     "start_time": "2023-08-16T18:36:13.820805Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1066"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:37:47.211742Z",
     "start_time": "2023-08-16T18:37:47.158254Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:37:51.243766Z",
     "start_time": "2023-08-16T18:37:51.194464Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:38:33.131228Z",
     "start_time": "2023-08-16T18:38:33.059320Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCDropout(layer.rate) if isinstance(layer, keras.layers.Dropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T18:38:37.245050Z",
     "start_time": "2023-08-16T18:38:37.190737Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_10 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.02, 0.2 , 0.03, 0.11, 0.25, 0.06, 0.03, 0.03, 0.08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal',\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation='selu', kernel_initializer='lecun_normal',\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4750 - accuracy: 0.8338 - val_loss: 0.3641 - val_accuracy: 0.8714\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3530 - accuracy: 0.8710 - val_loss: 0.3735 - val_accuracy: 0.8608\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제\n",
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation='elu',\n",
    "                                 kernel_initializer='he_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 48s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('my_cifar10_model.h5', save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, 'my_cifar10_logs', 'run_{:03d}'.format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12115), started 0:07:27 ago. (Use '!kill 12115' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-58196ac5880917fc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-58196ac5880917fc\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 5ms/step - loss: 4.1739 - accuracy: 0.1568 - val_loss: 2.1921 - val_accuracy: 0.2088\n",
      "Epoch 2/100\n",
      "  23/1407 [..............................] - ETA: 6s - loss: 2.2325 - accuracy: 0.1984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taemin/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 7s 5ms/step - loss: 2.0822 - accuracy: 0.2288 - val_loss: 2.2291 - val_accuracy: 0.1994\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9655 - accuracy: 0.2726 - val_loss: 1.9904 - val_accuracy: 0.2636\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8910 - accuracy: 0.3024 - val_loss: 2.0011 - val_accuracy: 0.2902\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8217 - accuracy: 0.3381 - val_loss: 1.8401 - val_accuracy: 0.3308\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7597 - accuracy: 0.3636 - val_loss: 1.7582 - val_accuracy: 0.3580\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7162 - accuracy: 0.3798 - val_loss: 1.7414 - val_accuracy: 0.3570\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6785 - accuracy: 0.3943 - val_loss: 1.6732 - val_accuracy: 0.3954\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6494 - accuracy: 0.4072 - val_loss: 1.6520 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6263 - accuracy: 0.4124 - val_loss: 1.6739 - val_accuracy: 0.3946\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6023 - accuracy: 0.4203 - val_loss: 1.6712 - val_accuracy: 0.3982\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5824 - accuracy: 0.4290 - val_loss: 1.6288 - val_accuracy: 0.4052\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5671 - accuracy: 0.4342 - val_loss: 1.6394 - val_accuracy: 0.4060\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5489 - accuracy: 0.4401 - val_loss: 1.6102 - val_accuracy: 0.4224\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5327 - accuracy: 0.4477 - val_loss: 1.5871 - val_accuracy: 0.4284\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5171 - accuracy: 0.4513 - val_loss: 1.5852 - val_accuracy: 0.4276\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5046 - accuracy: 0.4593 - val_loss: 1.5920 - val_accuracy: 0.4352\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4928 - accuracy: 0.4615 - val_loss: 1.5666 - val_accuracy: 0.4454\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4809 - accuracy: 0.4668 - val_loss: 1.5813 - val_accuracy: 0.4350\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4710 - accuracy: 0.4696 - val_loss: 1.5860 - val_accuracy: 0.4340\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4564 - accuracy: 0.4759 - val_loss: 1.5911 - val_accuracy: 0.4334\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4448 - accuracy: 0.4802 - val_loss: 1.5562 - val_accuracy: 0.4454\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4323 - accuracy: 0.4851 - val_loss: 1.5722 - val_accuracy: 0.4378\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4237 - accuracy: 0.4874 - val_loss: 1.5557 - val_accuracy: 0.4450\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4150 - accuracy: 0.4930 - val_loss: 1.5480 - val_accuracy: 0.4514\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4039 - accuracy: 0.4950 - val_loss: 1.5550 - val_accuracy: 0.4398\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3916 - accuracy: 0.4976 - val_loss: 1.5440 - val_accuracy: 0.4554\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3874 - accuracy: 0.5032 - val_loss: 1.5317 - val_accuracy: 0.4532\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3780 - accuracy: 0.5055 - val_loss: 1.5199 - val_accuracy: 0.4712\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3672 - accuracy: 0.5085 - val_loss: 1.5298 - val_accuracy: 0.4624\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3608 - accuracy: 0.5096 - val_loss: 1.5875 - val_accuracy: 0.4498\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3507 - accuracy: 0.5155 - val_loss: 1.5347 - val_accuracy: 0.4626\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3422 - accuracy: 0.5172 - val_loss: 1.5418 - val_accuracy: 0.4630\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3350 - accuracy: 0.5181 - val_loss: 1.5251 - val_accuracy: 0.4662\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3220 - accuracy: 0.5261 - val_loss: 1.5281 - val_accuracy: 0.4568\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3201 - accuracy: 0.5252 - val_loss: 1.5505 - val_accuracy: 0.4590\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3098 - accuracy: 0.5294 - val_loss: 1.5330 - val_accuracy: 0.4722\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2987 - accuracy: 0.5337 - val_loss: 1.5255 - val_accuracy: 0.4656\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2924 - accuracy: 0.5353 - val_loss: 1.5455 - val_accuracy: 0.4576\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2857 - accuracy: 0.5376 - val_loss: 1.5601 - val_accuracy: 0.4596\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2782 - accuracy: 0.5417 - val_loss: 1.5436 - val_accuracy: 0.4614\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2713 - accuracy: 0.5437 - val_loss: 1.5320 - val_accuracy: 0.4752\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2590 - accuracy: 0.5492 - val_loss: 1.5460 - val_accuracy: 0.4624\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2536 - accuracy: 0.5476 - val_loss: 1.5359 - val_accuracy: 0.4662\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2481 - accuracy: 0.5500 - val_loss: 1.5364 - val_accuracy: 0.4718\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2390 - accuracy: 0.5549 - val_loss: 1.5323 - val_accuracy: 0.4726\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2308 - accuracy: 0.5576 - val_loss: 1.5585 - val_accuracy: 0.4700\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2233 - accuracy: 0.5602 - val_loss: 1.5414 - val_accuracy: 0.4750\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2160 - accuracy: 0.5642 - val_loss: 1.5398 - val_accuracy: 0.4712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29be781c0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.5199 - accuracy: 0.4712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5199028253555298, 0.47119998931884766]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('my_cifar10_model.h5')\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "# c\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('my_cifar10_bn_model.h5', save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = os.path.join(os.curdir, 'my_cifar10_logs', 'run_bn_{:03d}'.format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 16s 9ms/step - loss: 1.8357 - accuracy: 0.3436 - val_loss: 1.6560 - val_accuracy: 0.4132\n",
      "Epoch 2/100\n",
      "   8/1407 [..............................] - ETA: 11s - loss: 1.7158 - accuracy: 0.3711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taemin/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6618 - accuracy: 0.4054 - val_loss: 1.5911 - val_accuracy: 0.4350\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5968 - accuracy: 0.4321 - val_loss: 1.5796 - val_accuracy: 0.4216\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5514 - accuracy: 0.4480 - val_loss: 1.5229 - val_accuracy: 0.4614\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5114 - accuracy: 0.4649 - val_loss: 1.4458 - val_accuracy: 0.4878\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4695 - accuracy: 0.4792 - val_loss: 1.4436 - val_accuracy: 0.4886\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4374 - accuracy: 0.4879 - val_loss: 1.4102 - val_accuracy: 0.4956\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4090 - accuracy: 0.5012 - val_loss: 1.3769 - val_accuracy: 0.5056\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3859 - accuracy: 0.5115 - val_loss: 1.3713 - val_accuracy: 0.5132\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3630 - accuracy: 0.5176 - val_loss: 1.3729 - val_accuracy: 0.5114\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3423 - accuracy: 0.5261 - val_loss: 1.3514 - val_accuracy: 0.5216\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3187 - accuracy: 0.5346 - val_loss: 1.3969 - val_accuracy: 0.4952\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2975 - accuracy: 0.5398 - val_loss: 1.3869 - val_accuracy: 0.5130\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2831 - accuracy: 0.5470 - val_loss: 1.3708 - val_accuracy: 0.5132\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2634 - accuracy: 0.5535 - val_loss: 1.3674 - val_accuracy: 0.5272\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 927s 660ms/step - loss: 1.2489 - accuracy: 0.5572 - val_loss: 1.3213 - val_accuracy: 0.5386\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2340 - accuracy: 0.5633 - val_loss: 1.3092 - val_accuracy: 0.5430\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2133 - accuracy: 0.5702 - val_loss: 1.3473 - val_accuracy: 0.5314\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2042 - accuracy: 0.5750 - val_loss: 1.3478 - val_accuracy: 0.5296\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1903 - accuracy: 0.5833 - val_loss: 1.3608 - val_accuracy: 0.5220\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1693 - accuracy: 0.5868 - val_loss: 1.3636 - val_accuracy: 0.5216\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1602 - accuracy: 0.5910 - val_loss: 1.3615 - val_accuracy: 0.5186\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1494 - accuracy: 0.5954 - val_loss: 1.3179 - val_accuracy: 0.5448\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1351 - accuracy: 0.5995 - val_loss: 1.3060 - val_accuracy: 0.5514\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1231 - accuracy: 0.6034 - val_loss: 1.3177 - val_accuracy: 0.5434\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1128 - accuracy: 0.6073 - val_loss: 1.3332 - val_accuracy: 0.5346\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0974 - accuracy: 0.6158 - val_loss: 1.3340 - val_accuracy: 0.5398\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0939 - accuracy: 0.6153 - val_loss: 1.3255 - val_accuracy: 0.5394\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0850 - accuracy: 0.6189 - val_loss: 1.3085 - val_accuracy: 0.5532\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0689 - accuracy: 0.6240 - val_loss: 1.3231 - val_accuracy: 0.5446\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0601 - accuracy: 0.6271 - val_loss: 1.3432 - val_accuracy: 0.5404\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0474 - accuracy: 0.6287 - val_loss: 1.3688 - val_accuracy: 0.5354\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0390 - accuracy: 0.6343 - val_loss: 1.3651 - val_accuracy: 0.5414\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0304 - accuracy: 0.6380 - val_loss: 1.3492 - val_accuracy: 0.5516\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0194 - accuracy: 0.6419 - val_loss: 1.3332 - val_accuracy: 0.5498\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0116 - accuracy: 0.6454 - val_loss: 1.3583 - val_accuracy: 0.5434\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9995 - accuracy: 0.6469 - val_loss: 1.3702 - val_accuracy: 0.5314\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9983 - accuracy: 0.6500 - val_loss: 1.3573 - val_accuracy: 0.5420\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9873 - accuracy: 0.6514 - val_loss: 1.3715 - val_accuracy: 0.5474\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9706 - accuracy: 0.6582 - val_loss: 1.3814 - val_accuracy: 0.5304\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9670 - accuracy: 0.6579 - val_loss: 1.3440 - val_accuracy: 0.5538\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9540 - accuracy: 0.6665 - val_loss: 1.3634 - val_accuracy: 0.5450\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9526 - accuracy: 0.6642 - val_loss: 1.3733 - val_accuracy: 0.5478\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9399 - accuracy: 0.6693 - val_loss: 1.3819 - val_accuracy: 0.5334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x171a64640>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3060 - accuracy: 0.5514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.305954098701477, 0.5514000058174133]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('my_cifar10_bn_model.h5')\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer='lecun_normal',\n",
    "                                 activation='selu'))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # 모델을 훈련할 때마다 증가시킴\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 5ms/step - loss: 1.9632 - accuracy: 0.2910 - val_loss: 1.8360 - val_accuracy: 0.3216\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7829 - accuracy: 0.3582 - val_loss: 1.8421 - val_accuracy: 0.3406\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6927 - accuracy: 0.3954 - val_loss: 1.8173 - val_accuracy: 0.3756\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.6389 - accuracy: 0.4183 - val_loss: 1.7328 - val_accuracy: 0.3984\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5956 - accuracy: 0.4332 - val_loss: 1.7413 - val_accuracy: 0.3900\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5574 - accuracy: 0.4491 - val_loss: 1.6221 - val_accuracy: 0.4246\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5153 - accuracy: 0.4639 - val_loss: 1.6279 - val_accuracy: 0.4464\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4781 - accuracy: 0.4813 - val_loss: 1.5551 - val_accuracy: 0.4402\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4465 - accuracy: 0.4873 - val_loss: 1.5982 - val_accuracy: 0.4478\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4188 - accuracy: 0.5011 - val_loss: 1.6147 - val_accuracy: 0.4652\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3874 - accuracy: 0.5119 - val_loss: 1.6421 - val_accuracy: 0.4624\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3595 - accuracy: 0.5231 - val_loss: 1.5806 - val_accuracy: 0.4666\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3334 - accuracy: 0.5335 - val_loss: 1.5828 - val_accuracy: 0.4738\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3130 - accuracy: 0.5374 - val_loss: 1.5329 - val_accuracy: 0.4782\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.2911 - accuracy: 0.5521 - val_loss: 1.6319 - val_accuracy: 0.4762\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2559 - accuracy: 0.5624 - val_loss: 1.7115 - val_accuracy: 0.4878\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2314 - accuracy: 0.5711 - val_loss: 1.6339 - val_accuracy: 0.4678\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2162 - accuracy: 0.5756 - val_loss: 1.5533 - val_accuracy: 0.4904\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1965 - accuracy: 0.5851 - val_loss: 1.6420 - val_accuracy: 0.4978\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 4.4253 - accuracy: 0.5733 - val_loss: 1.6079 - val_accuracy: 0.4840\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 9.8134 - accuracy: 0.5439 - val_loss: 1.5989 - val_accuracy: 0.4620\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2419 - accuracy: 0.5621 - val_loss: 1.6154 - val_accuracy: 0.4844\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1975 - accuracy: 0.5782 - val_loss: 1.5801 - val_accuracy: 0.4802\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1739 - accuracy: 0.5868 - val_loss: 1.5787 - val_accuracy: 0.4968\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1506 - accuracy: 0.5958 - val_loss: 1.6370 - val_accuracy: 0.4906\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1311 - accuracy: 0.6044 - val_loss: 1.6080 - val_accuracy: 0.4796\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.1137 - accuracy: 0.6108 - val_loss: 1.5972 - val_accuracy: 0.4930\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0997 - accuracy: 0.6168 - val_loss: 1.5965 - val_accuracy: 0.4806\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0851 - accuracy: 0.6232 - val_loss: 1.6650 - val_accuracy: 0.4928\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0832 - accuracy: 0.6270 - val_loss: 1.6705 - val_accuracy: 0.4998\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0641 - accuracy: 0.6312 - val_loss: 1.5960 - val_accuracy: 0.5012\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0582 - accuracy: 0.6357 - val_loss: 1.7624 - val_accuracy: 0.5032\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0539 - accuracy: 0.6359 - val_loss: 1.6175 - val_accuracy: 0.5156\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.0514 - accuracy: 0.6372 - val_loss: 1.6310 - val_accuracy: 0.4986\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.5329 - accuracy: 0.4782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5329430103302002, 0.4781999886035919]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model('my_cifar10_selu_model.h5')\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n",
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4782"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
