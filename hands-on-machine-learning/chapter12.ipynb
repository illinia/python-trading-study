{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version은 코랩 명령입니다.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 이 노트북은 텐서플로 ≥2.4이 필요합니다\n",
    "# 2.x 버전은 대부분 동일한 결과를 만들지만 몇 가지 버그가 있습니다.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b'hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'cafe'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant('cafe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 101], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in 'cafe'])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, 'UTF-8')\n",
    "tf.strings.length(b, unit='UTF8_CHAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 101], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit='UTF8_CHAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, 'UTF8')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{function_node __wrapped__SparseToDense_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense] name: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 14:07:36.965275: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at sparse_to_dense_op.cc:161 : INVALID_ARGUMENT: indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 4,  5,  6],\n",
       "       [ 9, 10,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 4,  6],\n",
       "       [10,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set2, set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2868a5f30>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), 'b-', linewidth=2, label='huber($z$)')\n",
    "plt.plot(z, z**2 / 2, 'b:', linewidth=1, label=r'$\\frac{1}{2}z^2$')\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal',\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 64/363 [====>.........................] - ETA: 0s - loss: 1.4767 - mae: 1.9367  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6016 - mae: 0.9578 - val_loss: 0.3049 - val_mae: 0.5961\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.2108 - mae: 0.5052 - val_loss: 0.2539 - val_mae: 0.5440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x286da5720>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 요소를 가진 모델을 저장하고 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taemin/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model_with_a_custom_loss.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_model_with_a_custom_loss.h5',\n",
    "                                custom_objects={'huber_fn': huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2014 - mae: 0.4925 - val_loss: 0.2014 - val_mae: 0.4845\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 735us/step - loss: 0.1951 - mae: 0.4832 - val_loss: 0.1847 - val_mae: 0.4687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2877f4a90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 963us/step - loss: 0.2175 - mae: 0.4843 - val_loss: 0.1975 - val_mae: 0.4576\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.2133 - mae: 0.4800 - val_loss: 0.1985 - val_mae: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28a06c670>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_with_a_custom_loss_threshold.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_model_with_a_custom_loss_threshold.h5',\n",
    "                                custom_objects={'huber_fn': create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 932us/step - loss: 0.2107 - mae: 0.4764 - val_loss: 0.2125 - val_mae: 0.4605\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.2069 - mae: 0.4712 - val_loss: 0.2206 - val_mae: 0.4712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x287000fd0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal',\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 953us/step - loss: 0.8471 - mae: 0.9586 - val_loss: 0.3918 - val_mae: 0.5935\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 739us/step - loss: 0.2506 - mae: 0.5208 - val_loss: 0.3065 - val_mae: 0.5339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2870934f0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.2310 - mae: 0.5004 - val_loss: 0.2195 - val_mae: 0.4773\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.2215 - mae: 0.4904 - val_loss: 0.2373 - val_mae: 0.4898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28c1e5150>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 557us/step - loss: 2.7486 - huber_fn: 1.1043\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.5834 - huber_fn: 0.2631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x287153130>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 0s 571us/step - loss: 0.1137 - huber_fn: 0.2293\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.1091 - huber_fn: 0.2201\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11365968734025955, 0.11377790814861516)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='selu', kernel_initializer='lecun_normal',\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer='nadam', metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 554us/step - loss: 0.9915 - huber_metric: 0.9915\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 595us/step - loss: 0.2419 - huber_metric: 0.2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x289e93d00>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 700us/step - loss: 0.5001 - HuberMetric: 1.0077\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.1290 - HuberMetric: 0.2600\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='glorot_normal'\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units], initializer='zeros'\n",
    "        )\n",
    "        super().build(batch_input_shape)\n",
    "    \n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'units': self.units,\n",
    "                'activation': keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation='relu', input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5046 - val_loss: 0.8473\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.5284 - val_loss: 0.6126\n",
      "162/162 [==============================] - 0s 455us/step - loss: 0.4642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46424275636672974"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    \n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation='elu',\n",
    "                                          kernel_initializer='he_normal')\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation='elu',\n",
    "                                          kernel_initializer='he_normal')\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 3.1943\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.8626\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.6017\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.4389\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.4999\n",
      "162/162 [==============================] - 0s 606us/step - loss: 0.7366\n",
      "162/162 [==============================] - 0s 548us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구성 요소에 기반한 손실과 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation='selu',\n",
    "                                          kernel_initializer='lecun_normal')\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruct = keras.layers.Dense(8)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name='reconstruction_error')\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        self.recon_loss = 0.05 * tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        \n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=[self.recon_loss])\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 895us/step - loss: 0.7458 - reconstruction_error: 0.0000e+00\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4054 - reconstruction_error: 0.0000e+00\n",
      "162/162 [==============================] - 0s 468us/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분을 사용하여 그레이디언트 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1**2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # tf.nn.softplus(z) 값을 반환합니다\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # tf.nn.relu(weights) 값을 반환합니다\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 훈련 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = ' - '.join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                          for m in [loss] + (metrics or [])])\n",
    "    end = '' if iteration < total else '\\n'\n",
    "    print('\\r{}/{} - '.format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/50 - loss: 0.5208 - mean_square: 7.5000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name='loss')\n",
    "mean_square = keras.metrics.Mean(name='mean_square')\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = '>' if running else '='\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = '{{:-{}d}}/{{}} [{{}}]'.format(len(str(total)))\n",
    "    params = [iteration, total, '=' * p + c + '.' * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = '-'.join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                        for m in [loss] + (metrics or [])])\n",
    "    end = '' if iteration < total else '\\n'\n",
    "    print('\\r{} - {}'.format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900-mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.8100-mean_absolute_error: 0.62075\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6871-mean_absolute_error: 0.5267\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6305-mean_absolute_error: 0.5173\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6430-mean_absolute_error: 0.5215\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6536-mean_absolute_error: 0.5271\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print('Epoch {}/{}'.format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF 함수가 계산 그래프를 추출하기 위해 파이썬 함수를 트레이싱하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print('print:', x)\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function tf_cube at 0x29298ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function tf_cube at 0x29298ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function tf_cube at 0x29298ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function tf_cube at 0x29298ec20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]]))\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]]))\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print('트레이싱', images)\n",
    "    return images[:, ::2, ::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트레이싱 Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1)\n",
    "preprocessed_images = shrink(img_batch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding inputs to tf.function `shrink` failed due to `Can not cast TensorSpec(shape=(2, 2, 2), dtype=tf.float32, name=None) to TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)`. Received args: (<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
      "array([[[0.43555546, 0.52486527],\n",
      "        [0.49674678, 0.06710219]],\n",
      "\n",
      "       [[0.35815144, 0.5931845 ],\n",
      "        [0.8396933 , 0.32720697]]], dtype=float32)>,) and kwargs: {} for signature: (images: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2,2,2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제\n",
    "### 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha', shape=batch_input_shape[-1:],\n",
    "            initializer='ones'\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta', shape=batch_input_shape[-1:],\n",
    "            initializer='zeros'\n",
    "        )\n",
    "        super().build(batch_input_shape)\n",
    "    \n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'eps': self.eps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.3941788e-08>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.7779177e-08>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280499a0a1974d23a3fefa681b4fa827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e647277488141328188ec810eed302e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529f5458c92747aca8b7492ad44bd238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19a1e51ad934c2383e9dd0c35ea8162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7229cea5a2354548b837a8909cc8ce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ef32f748ba4d63a318f1ee86ac56f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc='All epochs') as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc='epoch {}/{}'.format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                # print('loss:', loss)\n",
    "                # print('model.trainable_variables:', model.trainable_variables)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status['loss'] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status['val_loss'] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status['val_accuracy'] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred\n",
    "            ))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation='relu')\n",
    "])\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n"
     ]
    }
   ],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccee064556840cd9ccc7c5ff9cc2145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a662027cbba4904922f6dcf3570baa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aaad575fb5457887ba187a39145c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29006ee3517449a3807f83dc633a4a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b196dfe048491d97bbd00661012084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd2e9a9961742bda77101731800caf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
